{
 "cells": [
  {
   "cell_type": "raw",
   "id": "1b769bc3-2241-4c92-9cf5-c0afdfb942a5",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Harika Pamulapati\n",
    "Week 5 Assignment - Dask Programming\n",
    "High Performance Computing - HDS 5230"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c319806d-5b58-4f6f-b231-fb6a90d56b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b65fcdf4-dfe7-4a5a-9007-5e5510904486",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dd.read_csv('timeseries.csv', \n",
    "                 dtype={\n",
    "                     'population': 'float64',\n",
    "                     'cases': 'float64',\n",
    "                     'deaths': 'float64',\n",
    "                     'aggregate': 'object',\n",
    "                     'city': 'object',\n",
    "                     'country': 'object',\n",
    "                     'county': 'object',\n",
    "                     'level': 'object',\n",
    "                     'state': 'object',\n",
    "                     'lat': 'float64',\n",
    "                     'long': 'float64'\n",
    "                 },\n",
    "                 low_memory=False)\n",
    "\n",
    "df['date'] = dd.to_datetime(df['date'])\n",
    "mask = (df['country'] == 'United States') & \\\n",
    "       (df['level'] == 'state') & \\\n",
    "       (df['date'] >= '2020-01-01') & \\\n",
    "       (df['date'] <= '2021-02-28')\n",
    "\n",
    "us_states_df = df[mask]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c058f6d2-23c0-4f37-8163-29949f1faa27",
   "metadata": {},
   "source": [
    "Parallelization effectively supports the processing of CSV data (df = dd.read_csv() and mask operations) because these operations work on large datasets independently without necessity of data sharing between workers. The data file splits into manageable portions that parallel workers can process separately without depending on other sections of the data. Such operations qualify as \"embarrassingly parallel\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee990572-cef6-4062-ae26-0a92a608c2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state\n",
      "New Jersey                      0.001712\n",
      "New York                        0.001280\n",
      "Connecticut                     0.001216\n",
      "Massachusetts                   0.001187\n",
      "Rhode Island                    0.000903\n",
      "Washington, D.C.                0.000791\n",
      "Louisiana                       0.000706\n",
      "Michigan                        0.000623\n",
      "Illinois                        0.000553\n",
      "Maryland                        0.000536\n",
      "Pennsylvania                    0.000527\n",
      "Delaware                        0.000520\n",
      "Indiana                         0.000392\n",
      "Mississippi                     0.000373\n",
      "Colorado                        0.000295\n",
      "New Hampshire                   0.000274\n",
      "Georgia                         0.000269\n",
      "Minnesota                       0.000253\n",
      "Ohio                            0.000248\n",
      "New Mexico                      0.000244\n",
      "Arizona                         0.000231\n",
      "Iowa                            0.000228\n",
      "Virginia                        0.000217\n",
      "Alabama                         0.000205\n",
      "Washington                      0.000178\n",
      "Florida                         0.000174\n",
      "Nevada                          0.000173\n",
      "Missouri                        0.000167\n",
      "California                      0.000160\n",
      "South Carolina                  0.000159\n",
      "Wisconsin                       0.000137\n",
      "Kentucky                        0.000135\n",
      "North Carolina                  0.000133\n",
      "Nebraska                        0.000129\n",
      "North Dakota                    0.000115\n",
      "South Dakota                    0.000109\n",
      "Oklahoma                        0.000100\n",
      "Kansas                          0.000095\n",
      "Arkansas                        0.000094\n",
      "Tennessee                       0.000094\n",
      "Texas                           0.000091\n",
      "Vermont                         0.000087\n",
      "Maine                           0.000080\n",
      "Utah                            0.000057\n",
      "West Virginia                   0.000051\n",
      "Idaho                           0.000050\n",
      "Oregon                          0.000050\n",
      "United States Virgin Islands    0.000048\n",
      "Wyoming                         0.000033\n",
      "Puerto Rico                     0.000032\n",
      "Guam                            0.000024\n",
      "Montana                         0.000015\n",
      "Hawaii                          0.000012\n",
      "Alaska                          0.000011\n",
      "Northern Mariana Islands        0.000000\n",
      "American Samoa                       NaN\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Convert population and cases to float\n",
    "us_states_df['population'] = us_states_df['population'].astype(float)\n",
    "us_states_df['cases'] = us_states_df['cases'].astype(float)\n",
    "us_states_df['deaths'] = us_states_df['deaths'].astype(float)\n",
    "\n",
    "state_deaths = us_states_df.groupby('state')['deaths'].agg(['min', 'max']).compute()\n",
    "state_avg_pop = us_states_df.groupby('state')['population'].mean().compute()\n",
    "total_deaths = state_deaths['max'] - state_deaths['min']\n",
    "per_capita_mortality = total_deaths / state_avg_pop\n",
    "\n",
    "mortality_ranking = per_capita_mortality.sort_values(ascending=False)\n",
    "print(mortality_ranking)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "765122ec-0dd8-440f-9a85-c63b8028a022",
   "metadata": {},
   "source": [
    "The per-capita mortality analysis using groupby operations on deaths and population data benefits from parallelization when it distributes the initial grouping process across different data segments to enable workers to independently calculate partial aggregate results. The last phase of result integration between all workers necessitates certain communication processes between them. While there are incidental delays in parallel operations, large datasets make parallel processing prove productive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ba65191-70fa-4cc5-8af9-7af1b852425a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Monthly CFR for first 5 states (first 5 months):\n",
      "state        Alabama    Alaska  American Samoa   Arizona  Arkansas\n",
      "date                                                              \n",
      "2020-01-31       NaN       NaN             NaN       NaN       NaN\n",
      "2020-02-29       NaN       NaN             NaN       NaN       NaN\n",
      "2020-03-31       NaN       NaN             NaN       NaN       NaN\n",
      "2020-04-30  4.252492       NaN             NaN       NaN  1.969528\n",
      "2020-05-31  3.301930  0.884956             NaN  4.744466  1.889764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91849\\AppData\\Local\\Temp\\ipykernel_17892\\1139110521.py:2: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_data = us_states_pd.set_index('date').groupby('state').resample('M').agg({\n"
     ]
    }
   ],
   "source": [
    "us_states_pd = us_states_df.compute()\n",
    "monthly_data = us_states_pd.set_index('date').groupby('state').resample('M').agg({\n",
    "    'cases': 'max',\n",
    "    'deaths': 'max'\n",
    "})\n",
    "\n",
    "# Calculate month-over-month changes\n",
    "monthly_changes = monthly_data.groupby('state').diff()\n",
    "\n",
    "monthly_cfr = (monthly_changes['deaths'] / monthly_changes['cases'] * 100)\n",
    "monthly_cfr = monthly_cfr.unstack('state')\n",
    "\n",
    "print(\"\\nMonthly CFR for first 5 states (first 5 months):\")\n",
    "print(monthly_cfr.iloc[:5, :5])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9f740f04-6e4d-4bc6-ae7c-fa8377cc0847",
   "metadata": {},
   "source": [
    "Resampling and month-over-month changes calculations prevent parallelization because they need time-based order and sequential data point processing. The dependencies between successive months in this calculation method restrict parallel processing since each month needs previously computed data. When processing time series operations it is more effective to rely on traditional pandas after filtering data into memory because the full dataset sequence must be accessible for each state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27950fdf-fe8c-4b65-8879-d07a246bcf55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 States by Total CFR Change:\n",
      "state\n",
      "United States Virgin Islands    66.666667\n",
      "Alaska                          40.884956\n",
      "Rhode Island                    31.083942\n",
      "New Jersey                      26.936583\n",
      "Pennsylvania                    20.208528\n",
      "New Hampshire                   11.869711\n",
      "Connecticut                     11.571058\n",
      "Delaware                        10.729251\n",
      "Missouri                        10.614211\n",
      "Michigan                        10.267054\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "cfr_changes = monthly_cfr.diff()\n",
    "\n",
    "# Aggregate absolute changes for ranking\n",
    "total_cfr_change = cfr_changes.abs().sum()\n",
    "cfr_change_ranking = total_cfr_change.sort_values(ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 States by Total CFR Change:\")\n",
    "print(cfr_change_ranking.head(10))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0713f6df-aeb8-4c3b-a381-9437fe7e7603",
   "metadata": {},
   "source": [
    "The last step for calculating differences and aggregating changes in CFR changes does not suit parallelization because it requires processing already combined monthly data that remains much smaller than the initial dataset. Due to overhead costs of distributing small datasets the advantages of parallel processing would most likely not justify the effort. The process of sequential month-to-month change calculation ensures that this step operates in a fully serial fashion.\n",
    "The sort_values operations for generating final ranks do not benefit from parallelization because element comparison during sorting requires data exchange between different sections of information. The combination of parallel sorting algorithms does not provide performance benefits due to the small state count (50) so any processing overhead becomes excessive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81413196-00f9-474d-b599-eb1cfb574cf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
